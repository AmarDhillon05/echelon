{
  "title": "CGCian Dream\u00b2 Bigger",
  "entries": [
    {
      "title": "Censor AI",
      "attatchments": {
        "Censor AI \u2013 screenshot 1": "//d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/388/697/datas/gallery.jpg",
        "Censor AI \u2013 screenshot 2": "//d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/388/703/datas/gallery.jpg",
        "Censor AI \u2013 screenshot 3": "//d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/388/704/datas/gallery.jpg",
        "Censor AI \u2013 screenshot 4": "//d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/388/705/datas/gallery.jpg",
        "Censor AI \u2013 screenshot 5": "//d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/388/706/datas/gallery.jpg",
        "null": "https://www.youtube.com/embed/epCRTlCXfpU?enablejsapi=1&hl=en_US&rel=0&start=&version=3&wmode=transparent"
      },
      "info": "\n<h1>Censor AI</h1>\n<h2>Inspiration</h2>\n<p>The idea for Censor AI came from the growing demand to make video content safe and appropriate for different age groups without compromising creativity. We noticed that manual censorship is time-consuming and inconsistent. Our goal was to create an AI-driven solution that automates this process efficiently.</p>\n<h2>What it does</h2>\n<p>Censor AI is a smart video censorship tool that:</p>\n<ul>\n<li>Automatically analyzes video content using AI.</li>\n<li>Applies censorship actions like <strong>blurring</strong>, <strong>trimming</strong>, and <strong>muting</strong> based on selected age categories (6+, 12+, 16+, 18+).</li>\n<li>Uses OpenAI to detect inappropriate visuals, actions, or language.</li>\n<li>Allows creators and platforms to customize content suitability with minimal manual effort.</li>\n</ul>\n<h2>How we built it</h2>\n<ul>\n<li><strong>Frontend</strong>: Developed with <strong>Next.js</strong> for a modern and responsive UI.</li>\n<li><strong>Backend</strong>: Built in <strong>Go (Golang)</strong> for high performance and concurrency in processing videos.</li>\n<li><strong>AI</strong>: Integrated <strong>OpenAI</strong> for natural language and vision-based content analysis.</li>\n<li><strong>Video Processing</strong>: Implemented logic to edit videos (blur, mute, trim) based on AI feedback and age filters.</li>\n</ul>\n<h2>Challenges we ran into</h2>\n<ul>\n<li>Reducing latency in frame-by-frame analysis without compromising censorship accuracy.</li>\n<li>Integrating AI models to handle both visual and audio content dynamically.</li>\n<li>Designing a clean user interface for quick review and re-edit.</li>\n<li>Balancing performance with cost in video processing pipelines.</li>\n</ul>\n<h2>Accomplishments that we're proud of</h2>\n<ul>\n<li>Successfully built an AI-powered censorship system capable of multi-level age-based filtering.</li>\n<li>Achieved efficient processing of long video files using Go routines and streaming.</li>\n<li>Created a user-friendly web interface with real-time preview features.</li>\n<li>Built a modular and scalable backend that can be easily extended.</li>\n</ul>\n<h2>What we learned</h2>\n<ul>\n<li>Handling real-time video content requires deep optimization in both backend logic and infrastructure.</li>\n<li>AI content analysis, when combined with solid engineering, can outperform manual moderation in speed and accuracy.</li>\n<li>Collaboration between frontend, backend, and AI logic is critical for building production-ready tools.</li>\n</ul>\n<h2>What's next for Censor AI</h2>\n<ul>\n<li>Optimize AI model selection and reduce video processing time further.</li>\n<li>Add support for more languages and regional content moderation.</li>\n<li>Integrate voice recognition to detect and censor abusive speech accurately.</li>\n<li>Release an open API for developers to use Censor AI in their own platforms.</li>\n<li>Collaborate with content platforms for real-world deployment and feedback.</li>\n</ul>\n",
      "links": {
        "software-urls": {
          "github.com": "https://github.com/agam1092005/censor-ai",
          "drive.google.com": "https://drive.google.com/file/d/1XuIm4jj4t3cPpgPGaEhKAOQ6o4NOCjSv/view?usp=sharing"
        }
      }
    },
    {
      "title": "Smart Waste Management Using CV and ML",
      "attatchments": {
        "null": "https://www.youtube.com/embed/gwKsm0-LqYw?enablejsapi=1&hl=en_US&rel=0&start=&version=3&wmode=transparent"
      },
      "info": "\n<p>Inspiration\nThe growing issue of inefficient waste management and its environmental impact inspired us to develop an AI-powered solution to streamline waste detection, classification, and disposal.</p>\n<p>What it does\nOur system uses Computer Vision (CV) and Machine Learning (ML) to detect, classify, and manage waste effectively, reducing manual intervention and promoting sustainable waste disposal practices.</p>\n<p>How we built it\nWe used Python for backend logic, TensorFlow for machine learning models, OpenCV for image processing, and a user-friendly interface for data visualization.</p>\n<p>Challenges we ran into\nDataset collection and preprocessing.</p>\n<p>Training an accurate ML model for waste classification.</p>\n<p>Ensuring seamless integration between hardware and software components.</p>\n<p>Accomplishments that we're proud of\nSuccessfully implemented an AI-based waste detection system with reliable accuracy, contributing towards sustainable waste management practices.</p>\n<p>What we learned\nWe gained valuable insights into AI/ML model training, integration with real-world systems, and overcoming technical deployment challenges.</p>\n<p>What's next for Smart Waste Management Using CV and ML\nScaling the system for industrial-level waste management.</p>\n<p>Enhancing accuracy with larger datasets.</p>\n<p>Developing a mobile app for real-time waste monitoring.</p>\n",
      "links": {
        "software-urls": {
          "tanmaywarkhede.github.io": "https://tanmaywarkhede.github.io/smart_waste_management/",
          "github.com": "https://github.com/TanmayWarkhede/smart_waste_management.git"
        }
      }
    },
    {
      "title": "NutriCare Agents",
      "attatchments": {
        "NutriCare Agents \u2013 screenshot 1": "//d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/406/971/datas/gallery.jpg",
        "null": "https://www.youtube.com/embed/6d3UbajcSWw?enablejsapi=1&hl=en_US&rel=0&start=&version=3&wmode=transparent"
      },
      "info": "\n<h1>Project Story: NutriCare Agents</h1>\n<h2>About the Project</h2>\n<p>The inspiration for this project stemmed from the pressing need to tackle nutrition-related health issues in Vietnam. With rising rates of non-communicable diseases like cardiovascular disease, type 2 diabetes, and digestive disorders, coupled with limited access to professional nutritional counseling, it became clear that a more accessible, personalized solution was needed. Many existing solutions did not take into account the unique cultural, regional, and socioeconomic factors that influence the dietary habits of the Vietnamese people.</p>\n<h3>Inspiration</h3>\n<p>The core inspiration for NutriCare Agents was to bridge the gap between scientific nutritional knowledge and culturally relevant, personalized advice. We wanted to create a system that goes beyond generic recommendations, offering tailored meal suggestions based on individual health conditions, dietary preferences, and budget constraints. Moreover, we aimed to make this system accessible to everyone, including those who face financial and physical barriers to professional nutrition services. The ultimate goal is to improve public health and quality of life through personalized, evidence-based nutrition advice.</p>\n<h3>What We Learned</h3>\n<p>Throughout the development of NutriCare Agents, we learned a great deal about AI orchestration, multi-modal systems, and the integration of advanced technologies in real-world applications. Key takeaways include:</p>\n<ul>\n<li><p><strong>AI Integration</strong>: The challenge of orchestrating multiple AI agents in a way that allows them to work seamlessly together was both technically challenging and intellectually rewarding. We learned to fine-tune various AI models for specific tasks (e.g., meal recommendations, nutritional analysis) while ensuring they could communicate with one another efficiently.</p></li>\n<li><p><strong>Graph Neural Networks (GNN)</strong>: Working with GNNs to personalize meal recommendations based on a user\u2019s health data and preferences was a complex but fascinating learning experience. We were able to use GNNs to analyze large datasets of Vietnamese dishes and ingredients, identifying patterns that allowed us to make tailored recommendations.</p></li>\n<li><p><strong>Cultural Sensitivity</strong>: We realized the importance of incorporating local cultural knowledge into the system. It was essential to understand Vietnamese culinary traditions, regional variations, and specific health concerns when designing the system\u2019s recommendations.</p></li>\n<li><p><strong>Multi-Modal Design</strong>: Building a system that supports voice commands, text-based input/output, and eventually image and video processing pushed us to think about how users interact with AI in various forms. Designing an intuitive and accessible user experience was crucial for the success of the platform.</p></li>\n</ul>\n<h3>How We Built the Project</h3>\n<p>We built NutriCare Agents by integrating several powerful technologies and APIs, leveraging both Google\u2019s AI stack and open-source frameworks. The architecture of the system includes:</p>\n<ul>\n<li><p><strong>Frontend</strong>: The user interface was developed using Next.js and React, with Tailwind CSS for styling, ensuring a responsive, modern design. Firebase Authentication was integrated for user account management.</p></li>\n<li><p><strong>Backend</strong>: Firebase Cloud Functions were used for the serverless backend, which allows us to scale the platform without worrying about infrastructure management. Firebase Realtime Database was employed to store user data and preferences, while Google Cloud Storage handled large media files such as images.</p></li>\n<li><p><strong>AI and Machine Learning</strong>: The heart of the system is the multi-agent AI framework built using LangChain and Google GenAI SDK. Each agent serves a specific function, such as grounding recommendations in nutritional science or applying logical inference. Graph Neural Networks were employed for personalized meal recommendations based on a large dataset of Vietnamese dishes.</p></li>\n<li><p><strong>Voice Interfaces</strong>: Google Speech-to-Text and Text-to-Speech APIs were integrated to provide voice commands and guidance to users. This feature is especially useful for users with disabilities or those who prefer voice interactions.</p></li>\n<li><p><strong>Maps Integration</strong>: We incorporated Google Maps JavaScript API and Places API to recommend nearby restaurants and food vendors offering dishes that match user preferences.</p></li>\n</ul>\n<h3>Challenges Faced</h3>\n<p>While building NutriCare Agents was an incredibly rewarding experience, there were several challenges along the way:</p>\n<ol>\n<li><p><strong>Data Scarcity</strong>: Gathering a comprehensive dataset of Vietnamese dishes and ingredients with nutritional information was a significant challenge. We had to scrape data from various sources and manually clean it to ensure accuracy.</p></li>\n<li><p><strong>Cultural Sensitivity</strong>: Ensuring that the recommendations aligned with the cultural and dietary preferences of the Vietnamese population required extensive research. It was important to avoid generic recommendations and instead reflect the diversity of regional cuisines and local food habits.</p></li>\n<li><p><strong>Multi-Agent Coordination</strong>: Orchestrating multiple AI agents, each with its own specialized task, was a complex technical challenge. Ensuring that the agents worked together cohesively required careful design and testing.</p></li>\n<li><p><strong>Scalability</strong>: As the platform evolved, we had to ensure that it could scale efficiently to handle large amounts of user data and provide fast, real-time responses. We optimized the system for performance, particularly the recommendation engine, which needed to generate personalized suggestions in a timely manner.</p></li>\n<li><p><strong>User Privacy</strong>: Since NutriCare Agents handles sensitive health data, we had to implement robust data privacy mechanisms. This included local data processing and user-controlled data management, which posed additional challenges in terms of system architecture.</p></li>\n</ol>\n<h3>Conclusion</h3>\n<p>The journey of building NutriCare Agents has been an incredibly fulfilling learning experience. Not only did we have the opportunity to work with cutting-edge AI technologies, but we also had the chance to make a tangible impact on improving health outcomes in Vietnam. By addressing the specific nutritional needs and challenges of the Vietnamese population, NutriCare Agents is helping to democratize access to personalized nutrition guidance. We look forward to continuing to enhance the platform and expand its reach to more users in the future.</p>\n",
      "links": {
        "software-urls": {
          "github.com": "https://github.com/technoob05/NutriCare_Agents?fbclid=IwZXh0bgNhZW0CMTEAAR5uGKH7EKSv5CUgY22Fji70sm8ZkD2WEW1Uz4x7wwXYR5_HjwRjygNkTXtRew_aem_TaNs9TLE9T8NCgx4Pdvn9w"
        }
      }
    }
  ]
}